{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_soup(url):\n",
    "    return BeautifulSoup(requests.get(url).text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrapSubs(url):\n",
    "    soup = make_soup(url)\n",
    "    \n",
    "    items = soup.find_all('li',{'class':'s-item'})\n",
    "    item_details = []\n",
    "    \n",
    "    for item in items:\n",
    "        try:\n",
    "            \n",
    "            detail_sec = item.find('div',{'class': 's-item__info'})\n",
    "            item_url = detail_sec.find('a').get('href')\n",
    "            item_descr = detail_sec.find('h3',{'class':'s-item__title'}).text\n",
    "            price_descr = []\n",
    "#             print(detail_sec)\n",
    "            img_sec = item.find('div',{'class':'s-item__image'})\n",
    "            img_url = img_sec.find('a').get('href')\n",
    "#             print(img_url)\n",
    "            \n",
    "            for des_pair in item.find_all('div',{'class':'s-item__detail'}):\n",
    "                text = des_pair.find('span').text\n",
    "#                 print(text)\n",
    "                price_descr.append(text)\n",
    "#             print('\\n\\n')\n",
    "#             print(item_descr, img_url, item_url, price_descr)\n",
    "            item_details.append([item_descr, img_url, item_url, price_descr])\n",
    "        except AttributeError:\n",
    "            pass\n",
    "    return item_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrapCategory(category, url):\n",
    "    out = []\n",
    "    \n",
    "    soup = make_soup(url)\n",
    "    subCatBlock = soup.find('div',{'class':'b-visualnav__grid'})\n",
    "    subCategories = subCatBlock.find_all('a')\n",
    "    title = subCatBlock.find_all('div', {'class':'b-visualnav__title'})\n",
    "#     print( title)\n",
    "    \n",
    "    for i in range(len(subCategories)):\n",
    "        url_sub = subCategories[i].get('href')\n",
    "        title_sub = title[i].text\n",
    "        data_sub = scrapSubs(url_sub)\n",
    "        print(f'\\n{title_sub}\\n')\n",
    "        if(len(data_sub)>0):\n",
    "            df = pd.DataFrame(np.array(data_sub))\n",
    "            print(data_sub)\n",
    "            \n",
    "            df.to_csv(title_sub+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scrapCategory(\"Clothes\", \"https://www.ebay.com/b/Fashion/bn_7000259856\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
